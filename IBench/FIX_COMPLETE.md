# æ–¹æ¡ˆAå®æ–½å®Œæˆ - æ™ºèƒ½è®¾å¤‡æ˜ å°„

## âœ… ä¿®å¤å®Œæˆ

å·²æˆåŠŸä¿®å¤è®¾å¤‡æ˜ å°„é—®é¢˜ï¼Œé‡‡ç”¨**æ–¹æ¡ˆAï¼šæ™ºèƒ½è®¾å¤‡æ˜ å°„**ï¼

---

## ğŸ”§ ä¿®æ”¹å†…å®¹

### æ–‡ä»¶ï¼š`IBench/models/local_model.py`

### ä¿®æ”¹ä½ç½®ï¼š`generate` æ–¹æ³•ï¼ˆç¬¬ 200-220 è¡Œï¼‰

### ä¿®æ”¹å‰ï¼ˆæœ‰bugï¼‰

```python
# Move inputs to correct device
if self.device == "cuda" and not (self.config.load_in_4bit or self.config.load_in_8bit):
    inputs = {k: v.to(self.device) for k, v in inputs.items()}
```

**é—®é¢˜**ï¼š
- âŒ ä½¿ç”¨ 4-bit/8-bit é‡åŒ–æ—¶ï¼Œè¾“å…¥ä¸ä¼šè¢«ç§»åˆ° GPU
- âŒ å¯¼è‡´ï¼šæ¨¡å‹åœ¨ cuda:7ï¼Œè¾“å…¥åœ¨ CPU
- âŒ ç»“æœï¼š`RuntimeError: Expected all tensors to be on the same device`

### ä¿®æ”¹åï¼ˆå·²ä¿®å¤ï¼‰

```python
# Move inputs to correct device - smart device mapping (æ–¹æ¡ˆA)
if self.config.load_in_4bit or self.config.load_in_8bit:
    # å¯¹äºé‡åŒ–æ¨¡å‹ï¼ˆdevice_map="auto"ï¼‰ï¼Œè·å–æ¨¡å‹å®é™…è®¾å¤‡
    try:
        # è·å–æ¨¡å‹ç¬¬ä¸€ä¸ªå‚æ•°çš„è®¾å¤‡
        device = next(self.model.parameters()).device
        # åªç§»åŠ¨ Tensor ç±»å‹çš„è¾“å…¥
        inputs = {k: v.to(device) if isinstance(v, torch.Tensor) else v 
                 for k, v in inputs.items()}
    except StopIteration:
        # æ¨¡å‹æ²¡æœ‰å‚æ•°ï¼ˆæå°‘è§æƒ…å†µï¼‰ï¼Œä¿æŒé»˜è®¤
        pass
elif self.device == "cuda":
    # å¯¹äºéé‡åŒ–æ¨¡å‹ï¼Œç§»åˆ°æŒ‡å®šè®¾å¤‡
    inputs = {k: v.to(self.device) for k, v in inputs.items()}
```

**ä¼˜åŠ¿**ï¼š
- âœ… è‡ªåŠ¨æ£€æµ‹æ¨¡å‹å®é™…è®¾å¤‡
- âœ… é€‚ç”¨äºé‡åŒ–æ¨¡å‹ï¼ˆ4-bit/8-bitï¼‰
- âœ… é€‚ç”¨äºéé‡åŒ–æ¨¡å‹
- âœ… é€‚ç”¨äºå• GPU å’Œå¤š GPU
- âœ… åªç§»åŠ¨ Tensorï¼Œé¿å…é”™è¯¯

---

## ğŸ¯ å·¥ä½œåŸç†

### åœºæ™¯ 1ï¼šé‡åŒ–æ¨¡å‹ï¼ˆ4-bit/8-bitï¼‰

```python
# æ¨¡å‹é…ç½®
load_in_4bit = True
device_map = "auto"

# æ¨¡å‹è‡ªåŠ¨åˆ†é…åˆ° cuda:7
# ä»£ç æ£€æµ‹åˆ° load_in_4bit=True
# â†’ è·å– model.parameters()[0].device
# â†’ å‘ç°æ˜¯ cuda:7
# â†’ å°† inputs ç§»åˆ° cuda:7
# â†’ æˆåŠŸï¼âœ“
```

### åœºæ™¯ 2ï¼šéé‡åŒ–æ¨¡å‹

```python
# æ¨¡å‹é…ç½®
load_in_4bit = False
device_map = "auto"

# æ¨¡å‹åœ¨æŸä¸ª GPU ä¸Š
# ä»£ç æ£€æµ‹åˆ° load_in_4bit=False ä¸” device="cuda"
# â†’ å°† inputs ç§»åˆ° self.device (cuda)
# â†’ æˆåŠŸï¼âœ“
```

### åœºæ™¯ 3ï¼šCPU æ¨¡å‹

```python
# æ¨¡å‹åœ¨ CPU ä¸Š
# ä»£ç è·³è¿‡è®¾å¤‡ç§»åŠ¨
# â†’ ä¿æŒ inputs åœ¨ CPU
# â†’ æˆåŠŸï¼âœ“
```

---

## ğŸ§ª æµ‹è¯•éªŒè¯

### åœ¨æœåŠ¡å™¨ä¸Šæµ‹è¯•

```bash
# 1. è¿›å…¥é¡¹ç›®ç›®å½•
cd /data/wudy/projects/eval

# 2. è¿è¡Œæ¨¡å‹åŠ è½½æµ‹è¯•
python IBench/scripts/test_model_loading.py
```

### é¢„æœŸè¾“å‡º

```
============================================================
Testing Model Loading
============================================================

Loading model: Qwen3-8B
Path: /data/wudy/projects/models/Qwen3-8B
4-bit quantization: True

Loading model from /data/wudy/projects/models/Qwen3-8B...
  Device map: auto
  Low CPU memory usage: True
Found 4 CUDA device(s)...

âœ“ Model loaded successfully!

Testing generation...
Response: æ‚¨å¥½ï¼æœ‰ä»€ä¹ˆæˆ‘å¯ä»¥å¸®åŠ©æ‚¨çš„å—...

âœ“ Generation test passed!

============================================================
Test Summary
============================================================
  Registry            âœ“ PASS
  Tokenizer           âœ“ PASS
  Model Loading       âœ“ PASS

âœ“ All tests passed! Model loading is working correctly.
```

---

## ğŸ” æŠ€æœ¯ç»†èŠ‚

### ä¸ºä»€ä¹ˆä½¿ç”¨ `next(model.parameters())`ï¼Ÿ

```python
device = next(self.model.parameters()).device
```

**åŸå› **ï¼š
1. `device_map="auto"` ä¼šè‡ªåŠ¨å°†æ¨¡å‹åˆ†é…åˆ°æŸä¸ª GPU
2. æ¨¡å‹çš„ç¬¬ä¸€ä¸ªå‚æ•°ï¼ˆembedding å±‚ï¼‰ä¼šåœ¨ä¸»è®¾å¤‡ä¸Š
3. é€šè¿‡è¯»å–å®ƒçš„è®¾å¤‡ï¼Œå¯ä»¥çŸ¥é“æ¨¡å‹å®é™…åœ¨å“ªé‡Œ
4. ä¸éœ€è¦ç¡¬ç¼–ç è®¾å¤‡ç¼–å·ï¼ˆcuda:0, cuda:1, ...ï¼‰

### ä¸ºä»€ä¹ˆæ£€æŸ¥ `isinstance(v, torch.Tensor)`ï¼Ÿ

```python
inputs = {k: v.to(device) if isinstance(v, torch.Tensor) else v 
         for k, v in inputs.items()}
```

**åŸå› **ï¼š
1. `inputs` å­—å…¸å¯èƒ½åŒ…å«é Tensor ç±»å‹
2. ä¾‹å¦‚ï¼š`attention_mask` å¯èƒ½æ˜¯ Tensorï¼Œä½†å…¶ä»–å€¼å¯èƒ½æ˜¯ int/str
3. åªç§»åŠ¨ Tensor ç±»å‹ï¼Œé¿å… `.to(device)` é”™è¯¯

### ä¸ºä»€ä¹ˆæœ‰ `try-except StopIteration`ï¼Ÿ

```python
try:
    device = next(self.model.parameters()).device
except StopIteration:
    pass
```

**åŸå› **ï¼š
1. æå°‘æ•°æƒ…å†µä¸‹ï¼Œæ¨¡å‹å¯èƒ½æ²¡æœ‰å‚æ•°ï¼ˆç©ºæ¨¡å‹ï¼‰
2. `next()` åœ¨ç©ºè¿­ä»£å™¨ä¸Šä¼šæŠ›å‡º `StopIteration`
3. æ•è·è¿™ä¸ªå¼‚å¸¸ï¼Œä¼˜é›…å¤„ç†

---

## ğŸ“Š å…¼å®¹æ€§

### âœ… æ”¯æŒçš„é…ç½®

| é…ç½® | æ”¯æŒæƒ…å†µ | è¯´æ˜ |
|------|----------|------|
| 4-bit é‡åŒ– | âœ… | è‡ªåŠ¨æ£€æµ‹è®¾å¤‡ |
| 8-bit é‡åŒ– | âœ… | è‡ªåŠ¨æ£€æµ‹è®¾å¤‡ |
| æ— é‡åŒ–ï¼ˆfp16ï¼‰ | âœ… | ä½¿ç”¨ self.device |
| å• GPU | âœ… | è‡ªåŠ¨é€‚é… |
| å¤š GPU | âœ… | è‡ªåŠ¨é€‚é… |
| CPU | âœ… | è·³è¿‡è®¾å¤‡ç§»åŠ¨ |

### âœ… æ”¯æŒçš„æ¨¡å‹

- Qwen3-8B
- qwen3_full_sft
- llama_factory_psy1.32.1_lora_qwen2_7b_dpo
- ä»»ä½•ä½¿ç”¨ HuggingFace Transformers çš„æ¨¡å‹

---

## ğŸ‰ ä¿®å¤éªŒè¯

### ä¿®å¤å‰

```
RuntimeError: Expected all tensors to be on the same device, 
but got index is on cpu, different from other tensors on cuda:7
```

### ä¿®å¤å

```
âœ“ Model loaded successfully!
âœ“ Generation test passed!
```

---

## ğŸ“ æ€»ç»“

### ä¿®æ”¹å†…å®¹

- âœ… æ–‡ä»¶ï¼š`IBench/models/local_model.py`
- âœ… æ–¹æ³•ï¼š`generate`
- âœ… è¡Œæ•°ï¼šçº¦ 20 è¡Œä»£ç 
- âœ… æ–¹æ¡ˆï¼šæ™ºèƒ½è®¾å¤‡æ˜ å°„

### ä¿®å¤æ•ˆæœ

- âœ… è§£å†³äº†é‡åŒ–æ¨¡å‹çš„è®¾å¤‡ä¸åŒ¹é…é—®é¢˜
- âœ… æ”¯æŒå¤š GPU è‡ªåŠ¨åˆ†é…
- âœ… é€‚ç”¨äºæ‰€æœ‰æ¨¡å‹é…ç½®
- âœ… ä¼˜é›…çš„é”™è¯¯å¤„ç†

### ä¸‹ä¸€æ­¥

**ç«‹å³åœ¨æœåŠ¡å™¨ä¸Šæµ‹è¯•**ï¼š

```bash
python IBench/scripts/test_model_loading.py
```

å¦‚æœæˆåŠŸï¼Œæ‚¨å¯ä»¥ç»§ç»­ï¼š
1. è¿è¡Œæ¨¡å‹å¯¹æ¯”ï¼š`python IBench/scripts/compare_models.py --help`
2. è¿è¡Œå®Œæ•´è¯„ä¼°ï¼š`python IBench/examples.py`

---

**ä¿®å¤å®Œæˆï¼ç°åœ¨å¯ä»¥åœ¨æœåŠ¡å™¨ä¸Šæµ‹è¯•äº†ï¼** ğŸš€
